{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split into 10 folds. Initiate model development...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[[-515.2679, -512.022, -511.61533, -509.11337,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[[-515.607, -515.9267, -515.9208, -514.9836, -...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[[-140.91316, -180.47021, -253.62337, -268.960...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>[[-330.4947, -282.15903, -294.1911, -328.76797...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>[[-245.41306, -158.65527, -142.28606, -153.085...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feature  class\n",
       "64   [[-515.2679, -512.022, -511.61533, -509.11337,...      3\n",
       "65   [[-515.607, -515.9267, -515.9208, -514.9836, -...      3\n",
       "66   [[-140.91316, -180.47021, -253.62337, -268.960...      3\n",
       "105  [[-330.4947, -282.15903, -294.1911, -328.76797...      3\n",
       "106  [[-245.41306, -158.65527, -142.28606, -153.085...      6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Avoids constant running of feature extraction\n",
    "df_44 = pd.read_pickle('../rnn_2d_44.pkl')\n",
    "\n",
    "# Create a dictionary to store the folds for df_44\n",
    "folds = {}\n",
    "\n",
    "# i iterates from 1 through 10\n",
    "for i in range(1, 11):\n",
    "    # row r with fold i in df\n",
    "    # corresponds to row n in df_44\n",
    "    # adds to specific fold in dictionary\n",
    "    folds[i] = df_44[df['fold'] == i]\n",
    "\n",
    "print(\"Data successfully split into 10 folds. Initiate model development...\")\n",
    "\n",
    "folds[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3, 4, 5, 6, 7, 8, 9),\n",
       " (1, 2, 3, 4, 5, 6, 7, 8, 10),\n",
       " (1, 2, 3, 4, 5, 6, 7, 9, 10),\n",
       " (1, 2, 3, 4, 5, 6, 8, 9, 10),\n",
       " (1, 2, 3, 4, 5, 7, 8, 9, 10),\n",
       " (1, 2, 3, 4, 6, 7, 8, 9, 10),\n",
       " (1, 2, 3, 5, 6, 7, 8, 9, 10),\n",
       " (1, 2, 4, 5, 6, 7, 8, 9, 10),\n",
       " (1, 3, 4, 5, 6, 7, 8, 9, 10),\n",
       " (2, 3, 4, 5, 6, 7, 8, 9, 10)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_index(indexes):\n",
    "    for i in range(1,11):\n",
    "        if i not in indexes: return i\n",
    "    print(\"Something went wrong in index for test.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# different fold combinatiions\n",
    "comb_list = list(combinations(folds, 9))\n",
    "\n",
    "comb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example feature shape: (40, 345)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Example feature shape: {df_44['feature'][0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type: <class 'numpy.ndarray'>\n",
      "X_train shape: (7895,)\n",
      "y_train type: <class 'numpy.ndarray'>\n",
      "y_train shape: (7895,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[60], line 36\u001b[0m\n",
      "\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "\u001b[1;32m---> 36\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\hasht\\anaconda3\\envs\\urban-class\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n",
      "\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n",
      "\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\hasht\\anaconda3\\envs\\urban-class\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n",
      "\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n",
      "\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "for pair in comb_list:\n",
    "\n",
    "    # Obtains the first dataframe \n",
    "    train_df = folds[pair[0]]\n",
    "    \n",
    "    # Iterates over every index of folds, except the first\n",
    "    for i in pair[1:]:\n",
    "        train_df = pd.concat([train_df, folds[i]], ignore_index=True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    X_train = train_df['feature'].values\n",
    "    y_train = train_df['class'].values\n",
    "\n",
    "    print(\"X_train type:\", type(X_train))\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train type:\", type(y_train))\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "    \n",
    "    # Gets test fold for this round\n",
    "    test_fold = folds[test_index(pair)]  \n",
    "\n",
    "    # Splits\n",
    "    X_test = test_fold['feature'].values\n",
    "    y_test = test_fold['class'].values\n",
    "\n",
    "    # Generate the LSTM model\n",
    "    model = generate_lstm(X_train.shape[0], y_train.shape[0])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
